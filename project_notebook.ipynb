{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fringe Speech, understanding the language of 4chan during the 2020 election"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql mysql://jeilers@localhost/?charset=utf8mb4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from termcolor import cprint\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def write_msgs_from_feat(feat_table, msg_f):\n",
    "    message_ids = %sql select distinct(group_id) from {feat_table}    \n",
    "    with open(msgs_f,'w') as msgs_fh:\n",
    "        for message_id in tqdm(message_ids,desc='msgs written'):\n",
    "            message_id = message_id[0]\n",
    "            feats = %sql select feat from {feat_table} where group_id = {message_id}\n",
    "            feats = map(operator.itemgetter(0),feats)\n",
    "            feats = ' '.join(feats)\n",
    "            msgs_fh.write(' '.join([str(message_id),'en',feats]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = 'jeilers_project'\n",
    "msgs_table = '4chan2'\n",
    "\n",
    "feat_1gram_table = 'feat$1gram$4chan2$message_id$16to16'\n",
    "feat_1gram_pruned_table = 'feat_pruned$1gram$4chan2$message_id$16to16'\n",
    "feat_1gram_0_0001_table = 'feat_pruned$1gram$4chan2$message_id$16to16$0_0001'\n",
    "\n",
    "msgs_lda_table = '4chan2_lda$topics'\n",
    "\n",
    "topics__fb_cp_table = 'topics_fb2k'\n",
    "topics__fb_freq_table = 'topics_fb2k_freq'\n",
    "feat_fb_table = 'feat$cat_topics_fb2k_w$4chan2$message_id$1gra'\n",
    "\n",
    "topics_cp_table = 'blog_authorship_cp'\n",
    "topic_ll_table = 'blog_authorship_freq'\n",
    "feat_hour_msg_table = 'feat$cat_blog_authorship_cp_w$4chan2$message_id$1gra'\n",
    "\n",
    "feat_LIWC_table = 'feat$cat_LIWC2015$4chan2$message_id$1gra'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql://jeilers@localhost/?charset=utf8mb4\n",
      "0 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql use {database}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql://jeilers@localhost/?charset=utf8mb4\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count(distinct(feat))</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>8273</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(8273,)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql select count(distinct(feat)) from {feat_1gram_0_0001_table}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql://jeilers@localhost/?charset=utf8mb4\n",
      "(MySQLdb._exceptions.OperationalError) (1068, 'Multiple primary key defined')\n",
      "[SQL: alter table 4chan2 add primary key message_id (message_id);]\n",
      "(Background on this error at: http://sqlalche.me/e/e3q8)\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "alter table {msgs_table} add primary key message_id (message_id);\n",
    "alter table {msgs_table} add index post_id (post_id);\n",
    "CREATE INDEX message ON {msgs_table} (message(100));\n",
    "alter table {msgs_table} add index date_time (date_time);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Outline of the steps needed\n",
    "- 2) dlatk extract 1grams\n",
    "- 3a) 1grams are written into mallet-readable msgs file in Python\n",
    "- 3b) mallet converts the above file to its own format for training a topic model  \n",
    "- ----------------------------------------\n",
    "- 4) mallet runs LDA and produces files --   **THIS IS THE ACTUAL TOPIC MODELING**  \n",
    "- ----------------------------------------\n",
    "- 5a) dlatk converts mallet output to an intermediate file\n",
    "- 5b) dlatk ingests mallet output files into mysql  \n",
    "- 5c) dlatk writes topic tables to files -- topic-given-word and word-given-topic\n",
    "- 5d) dlatk creates the two lexicon tables from the files it just produced -- topic-given-word and word-given-topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract 1 grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dlatkInterface.py \\\n",
    "    --corpdb {database} \\\n",
    "    --corptable {msgs_table} \\\n",
    "    --correl_field message_id \\\n",
    "    --add_ngrams -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above command produced table `feat$1gram$4chan2$message_id$16to16`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql://jeilers@localhost/?charset=utf8mb4\n",
      "0 rows affected.\n",
      "100 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>n</th>\n",
       "        <th>feat</th>\n",
       "        <th>n_occ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1</td>\n",
       "        <td>.</td>\n",
       "        <td>48134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2</td>\n",
       "        <td>the</td>\n",
       "        <td>32800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>3</td>\n",
       "        <td>,</td>\n",
       "        <td>27035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>4</td>\n",
       "        <td>!</td>\n",
       "        <td>21534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>5</td>\n",
       "        <td>?</td>\n",
       "        <td>20577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>6</td>\n",
       "        <td>to</td>\n",
       "        <td>19578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>7</td>\n",
       "        <td>and</td>\n",
       "        <td>17974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>8</td>\n",
       "        <td>a</td>\n",
       "        <td>17154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>9</td>\n",
       "        <td>is</td>\n",
       "        <td>15293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>10</td>\n",
       "        <td>/</td>\n",
       "        <td>14611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>11</td>\n",
       "        <td>in</td>\n",
       "        <td>12819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>12</td>\n",
       "        <td>i</td>\n",
       "        <td>12764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>13</td>\n",
       "        <td>you</td>\n",
       "        <td>12729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>14</td>\n",
       "        <td>of</td>\n",
       "        <td>12590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>15</td>\n",
       "        <td>&lt;newline&gt;</td>\n",
       "        <td>12224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>16</td>\n",
       "        <td>&gt;</td>\n",
       "        <td>10966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>17</td>\n",
       "        <td>trump</td>\n",
       "        <td>10765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>18</td>\n",
       "        <td>it</td>\n",
       "        <td>9487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>19</td>\n",
       "        <td>for</td>\n",
       "        <td>9244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>20</td>\n",
       "        <td>this</td>\n",
       "        <td>8529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>21</td>\n",
       "        <td>that</td>\n",
       "        <td>7831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>22</td>\n",
       "        <td>are</td>\n",
       "        <td>7712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>23</td>\n",
       "        <td>they</td>\n",
       "        <td>6190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>24</td>\n",
       "        <td>on</td>\n",
       "        <td>5957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>25</td>\n",
       "        <td>be</td>\n",
       "        <td>5389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>26</td>\n",
       "        <td>will</td>\n",
       "        <td>5016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>27</td>\n",
       "        <td>biden</td>\n",
       "        <td>4681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>28</td>\n",
       "        <td>have</td>\n",
       "        <td>4666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>29</td>\n",
       "        <td>not</td>\n",
       "        <td>4648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>30</td>\n",
       "        <td>all</td>\n",
       "        <td>4537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>31</td>\n",
       "        <td>he</td>\n",
       "        <td>4536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>32</td>\n",
       "        <td>with</td>\n",
       "        <td>4422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>33</td>\n",
       "        <td>we</td>\n",
       "        <td>4172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>34</td>\n",
       "        <td>but</td>\n",
       "        <td>4163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>35</td>\n",
       "        <td>my</td>\n",
       "        <td>4121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>36</td>\n",
       "        <td>&quot;</td>\n",
       "        <td>4119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>37</td>\n",
       "        <td>if</td>\n",
       "        <td>3961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>38</td>\n",
       "        <td>just</td>\n",
       "        <td>3951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>39</td>\n",
       "        <td>fuck</td>\n",
       "        <td>3910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>40</td>\n",
       "        <td>your</td>\n",
       "        <td>3848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>41</td>\n",
       "        <td>red</td>\n",
       "        <td>3753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>42</td>\n",
       "        <td>what</td>\n",
       "        <td>3711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>43</td>\n",
       "        <td>no</td>\n",
       "        <td>3654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>44</td>\n",
       "        <td>....</td>\n",
       "        <td>3606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>45</td>\n",
       "        <td>so</td>\n",
       "        <td>3606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>46</td>\n",
       "        <td>it&#x27;s</td>\n",
       "        <td>3544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>47</td>\n",
       "        <td>like</td>\n",
       "        <td>3485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>48</td>\n",
       "        <td>was</td>\n",
       "        <td>3384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>49</td>\n",
       "        <td>&gt;&gt;</td>\n",
       "        <td>3355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>50</td>\n",
       "        <td>fucking</td>\n",
       "        <td>3337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>51</td>\n",
       "        <td>as</td>\n",
       "        <td>3271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>52</td>\n",
       "        <td>vote</td>\n",
       "        <td>3146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>53</td>\n",
       "        <td>get</td>\n",
       "        <td>2751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>54</td>\n",
       "        <td>do</td>\n",
       "        <td>2745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>55</td>\n",
       "        <td>at</td>\n",
       "        <td>2738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>56</td>\n",
       "        <td>up</td>\n",
       "        <td>2720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>57</td>\n",
       "        <td>can</td>\n",
       "        <td>2658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>58</td>\n",
       "        <td>’</td>\n",
       "        <td>2629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>59</td>\n",
       "        <td>more</td>\n",
       "        <td>2608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>60</td>\n",
       "        <td>go</td>\n",
       "        <td>2586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>61</td>\n",
       "        <td>now</td>\n",
       "        <td>2555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>62</td>\n",
       "        <td>people</td>\n",
       "        <td>2514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>63</td>\n",
       "        <td>)</td>\n",
       "        <td>2499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>64</td>\n",
       "        <td>o</td>\n",
       "        <td>2488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>65</td>\n",
       "        <td>(</td>\n",
       "        <td>2448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>66</td>\n",
       "        <td>from</td>\n",
       "        <td>2446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>67</td>\n",
       "        <td>has</td>\n",
       "        <td>2445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>68</td>\n",
       "        <td>or</td>\n",
       "        <td>2429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>69</td>\n",
       "        <td>aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa</td>\n",
       "        <td>2390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>70</td>\n",
       "        <td>who</td>\n",
       "        <td>2380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>71</td>\n",
       "        <td>about</td>\n",
       "        <td>2334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>72</td>\n",
       "        <td>me</td>\n",
       "        <td>2302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>73</td>\n",
       "        <td>win</td>\n",
       "        <td>2291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>74</td>\n",
       "        <td>going</td>\n",
       "        <td>2291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>75</td>\n",
       "        <td>ooo</td>\n",
       "        <td>2282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>76</td>\n",
       "        <td>by</td>\n",
       "        <td>2264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>77</td>\n",
       "        <td>\\</td>\n",
       "        <td>2262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>78</td>\n",
       "        <td>over</td>\n",
       "        <td>2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>79</td>\n",
       "        <td>%</td>\n",
       "        <td>2244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>80</td>\n",
       "        <td>don&#x27;t</td>\n",
       "        <td>2237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>81</td>\n",
       "        <td>their</td>\n",
       "        <td>2231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>82</td>\n",
       "        <td>how</td>\n",
       "        <td>2211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>83</td>\n",
       "        <td>out</td>\n",
       "        <td>2176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>84</td>\n",
       "        <td>because</td>\n",
       "        <td>2128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>85</td>\n",
       "        <td>energy</td>\n",
       "        <td>2060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>86</td>\n",
       "        <td>even</td>\n",
       "        <td>2060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>87</td>\n",
       "        <td>here</td>\n",
       "        <td>2030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>88</td>\n",
       "        <td>why</td>\n",
       "        <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>89</td>\n",
       "        <td>based</td>\n",
       "        <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>90</td>\n",
       "        <td>shit</td>\n",
       "        <td>1965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>91</td>\n",
       "        <td>one</td>\n",
       "        <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>92</td>\n",
       "        <td>only</td>\n",
       "        <td>1923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>93</td>\n",
       "        <td>there</td>\n",
       "        <td>1919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>94</td>\n",
       "        <td>them</td>\n",
       "        <td>1892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>95</td>\n",
       "        <td>when</td>\n",
       "        <td>1861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>96</td>\n",
       "        <td>election</td>\n",
       "        <td>1825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>97</td>\n",
       "        <td>i&#x27;m</td>\n",
       "        <td>1818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>98</td>\n",
       "        <td>would</td>\n",
       "        <td>1787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>99</td>\n",
       "        <td>his</td>\n",
       "        <td>1786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>100</td>\n",
       "        <td>:</td>\n",
       "        <td>1778</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(1, '.', Decimal('48134')),\n",
       " (2, 'the', Decimal('32800')),\n",
       " (3, ',', Decimal('27035')),\n",
       " (4, '!', Decimal('21534')),\n",
       " (5, '?', Decimal('20577')),\n",
       " (6, 'to', Decimal('19578')),\n",
       " (7, 'and', Decimal('17974')),\n",
       " (8, 'a', Decimal('17154')),\n",
       " (9, 'is', Decimal('15293')),\n",
       " (10, '/', Decimal('14611')),\n",
       " (11, 'in', Decimal('12819')),\n",
       " (12, 'i', Decimal('12764')),\n",
       " (13, 'you', Decimal('12729')),\n",
       " (14, 'of', Decimal('12590')),\n",
       " (15, '<newline>', Decimal('12224')),\n",
       " (16, '>', Decimal('10966')),\n",
       " (17, 'trump', Decimal('10765')),\n",
       " (18, 'it', Decimal('9487')),\n",
       " (19, 'for', Decimal('9244')),\n",
       " (20, 'this', Decimal('8529')),\n",
       " (21, 'that', Decimal('7831')),\n",
       " (22, 'are', Decimal('7712')),\n",
       " (23, 'they', Decimal('6190')),\n",
       " (24, 'on', Decimal('5957')),\n",
       " (25, 'be', Decimal('5389')),\n",
       " (26, 'will', Decimal('5016')),\n",
       " (27, 'biden', Decimal('4681')),\n",
       " (28, 'have', Decimal('4666')),\n",
       " (29, 'not', Decimal('4648')),\n",
       " (30, 'all', Decimal('4537')),\n",
       " (31, 'he', Decimal('4536')),\n",
       " (32, 'with', Decimal('4422')),\n",
       " (33, 'we', Decimal('4172')),\n",
       " (34, 'but', Decimal('4163')),\n",
       " (35, 'my', Decimal('4121')),\n",
       " (36, '\"', Decimal('4119')),\n",
       " (37, 'if', Decimal('3961')),\n",
       " (38, 'just', Decimal('3951')),\n",
       " (39, 'fuck', Decimal('3910')),\n",
       " (40, 'your', Decimal('3848')),\n",
       " (41, 'red', Decimal('3753')),\n",
       " (42, 'what', Decimal('3711')),\n",
       " (43, 'no', Decimal('3654')),\n",
       " (44, '....', Decimal('3606')),\n",
       " (45, 'so', Decimal('3606')),\n",
       " (46, \"it's\", Decimal('3544')),\n",
       " (47, 'like', Decimal('3485')),\n",
       " (48, 'was', Decimal('3384')),\n",
       " (49, '>>', Decimal('3355')),\n",
       " (50, 'fucking', Decimal('3337')),\n",
       " (51, 'as', Decimal('3271')),\n",
       " (52, 'vote', Decimal('3146')),\n",
       " (53, 'get', Decimal('2751')),\n",
       " (54, 'do', Decimal('2745')),\n",
       " (55, 'at', Decimal('2738')),\n",
       " (56, 'up', Decimal('2720')),\n",
       " (57, 'can', Decimal('2658')),\n",
       " (58, '’', Decimal('2629')),\n",
       " (59, 'more', Decimal('2608')),\n",
       " (60, 'go', Decimal('2586')),\n",
       " (61, 'now', Decimal('2555')),\n",
       " (62, 'people', Decimal('2514')),\n",
       " (63, ')', Decimal('2499')),\n",
       " (64, 'o', Decimal('2488')),\n",
       " (65, '(', Decimal('2448')),\n",
       " (66, 'from', Decimal('2446')),\n",
       " (67, 'has', Decimal('2445')),\n",
       " (68, 'or', Decimal('2429')),\n",
       " (69, 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa', Decimal('2390')),\n",
       " (70, 'who', Decimal('2380')),\n",
       " (71, 'about', Decimal('2334')),\n",
       " (72, 'me', Decimal('2302')),\n",
       " (73, 'win', Decimal('2291')),\n",
       " (74, 'going', Decimal('2291')),\n",
       " (75, 'ooo', Decimal('2282')),\n",
       " (76, 'by', Decimal('2264')),\n",
       " (77, '\\\\', Decimal('2262')),\n",
       " (78, 'over', Decimal('2251')),\n",
       " (79, '%', Decimal('2244')),\n",
       " (80, \"don't\", Decimal('2237')),\n",
       " (81, 'their', Decimal('2231')),\n",
       " (82, 'how', Decimal('2211')),\n",
       " (83, 'out', Decimal('2176')),\n",
       " (84, 'because', Decimal('2128')),\n",
       " (85, 'energy', Decimal('2060')),\n",
       " (86, 'even', Decimal('2060')),\n",
       " (87, 'here', Decimal('2030')),\n",
       " (88, 'why', Decimal('2016')),\n",
       " (89, 'based', Decimal('1985')),\n",
       " (90, 'shit', Decimal('1965')),\n",
       " (91, 'one', Decimal('1941')),\n",
       " (92, 'only', Decimal('1923')),\n",
       " (93, 'there', Decimal('1919')),\n",
       " (94, 'them', Decimal('1892')),\n",
       " (95, 'when', Decimal('1861')),\n",
       " (96, 'election', Decimal('1825')),\n",
       " (97, \"i'm\", Decimal('1818')),\n",
       " (98, 'would', Decimal('1787')),\n",
       " (99, 'his', Decimal('1786')),\n",
       " (100, ':', Decimal('1778'))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SET @n = 0;\n",
    "select @n := @n + 1 n, a.* from \n",
    "    (select feat,sum(value) as n_occ from {feat_1gram_table} group by feat order by n_occ desc limit 100) as a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prune the table of its 75 most used words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "drop table if exists {feat_1gram_pruned_table};\n",
    "create table {feat_1gram_pruned_table} as\n",
    "(\n",
    "    select \n",
    "        A.* \n",
    "    from \n",
    "        {feat_1gram_table} as A,\n",
    "        (select \n",
    "             feat,\n",
    "             sum(value) as n_occ \n",
    "         from {feat_1gram_table} \n",
    "         group by feat \n",
    "         order by n_occ desc \n",
    "         LIMIT 999999999 OFFSET 75) as B\n",
    "    where A.feat = B.feat\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write 1grams into mallet-formatted msgs file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_d = '/home/jeilers/mallet_output'\n",
    "!mkdir -p {out_d}\n",
    "!rm -rf {out_d}/*\n",
    "msgs_f = f'{out_d}/msgs.txt'\n",
    "%sql alter table {feat_1gram_pruned_table} add index group_id (group_id)\n",
    "write_msgs_from_feat(feat_1gram_pruned_table,msgs_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mallet formats its msgs file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_msgs_f = f'{out_d}/msgs.mallet' \n",
    "\n",
    "!/shared/mallet/bin/mallet \\\n",
    "    import-file \\\n",
    "    --input {msgs_f} \\\n",
    "    --output {mallet_msgs_f} \\\n",
    "    --remove-stopwords \\\n",
    "    --keep-sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files mallet writes as its output after training topics. \n",
    "# Please refer to mallet docs for details on this command on what these files contain.\n",
    "model_f = f'{out_d}/mallet.model'\n",
    "state_f = f'{out_d}/state.gz'\n",
    "topic_keys_f = f'{out_d}/topic_keys.txt'\n",
    "doc_topics_f = f'{out_d}/doc_topics.txt'\n",
    "\n",
    "!/shared/mallet/bin/mallet \\\n",
    "    train-topics \\\n",
    "    --input {mallet_msgs_f} \\\n",
    "    --num-topics 20 \\\n",
    "    --output-model {model_f} \\\n",
    "    --output-state {state_f} \\\n",
    "    --output-topic-keys {topic_keys_f} \\\n",
    "    --output-doc-topics {doc_topics_f}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting Mallet output into DLATK tables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_f = f'{out_d}/topics'\n",
    "\n",
    "!dlatkInterface.py \\\n",
    "    --add_message_id {msgs_f} {state_f} \\\n",
    "    --output_name {topics_f}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dlatk ingest Mallet output into mysql to an intermediate table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dlatkInterface.py \\\n",
    "    --corpdb {database} \\\n",
    "    --corptable {msgs_table} \\\n",
    "    --add_lda_messages {topics_f}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above command produced table `4chan2$topics`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dlatk writes topic tables to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {out_d}\n",
    "\n",
    "!dlatkInterface.py \\\n",
    "    --corpdb {database} \\\n",
    "    --corptable {msgs_table} \\\n",
    "    --lda_msg_tbl '{msgs_lda_table}' \\\n",
    "    --create_dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above command produced csv files with prefix `4chan2*`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_given_word_f = f'{out_d}/4chan2_lda.topics.topicGivenWord.csv'\n",
    "loglik_f = f'{out_d}/4chan2_lda.topics.freq.threshed50.loglik.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dlatk imports topic files into its lexicon database\n",
    "\n",
    "dlatk can use the csv file `*topicGivenWord.csv` to create the lexicon table topic-given-word -- this is the table we use for extraction of dictionaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dlatkInterface.py \\\n",
    "    --lex_interface \\\n",
    "    --topic_csv \\\n",
    "    --topicfile {topic_given_word_f} \\\n",
    "    --create blog_authorship_cp \\\n",
    "    --lexicondb {database}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select * from blog_authorship_cp order by rand() limit 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dlatk can use the csv file `*loglik.csv` to create the lexicon table word-given-topic -- this is the table we use for visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dlatkInterface.py \\\n",
    "    --lex_interface \\\n",
    "    --topic_csv \\\n",
    "    --topicfile {loglik_f} \\\n",
    "    --create blog_authorship_freq \\\n",
    "    --lexicondb {database}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select * from blog_authorship_freq order by rand() limit 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the two tables:\n",
    "- `blog_authorship_cp`\n",
    "- `blog_authorship_freq`\n",
    "\n",
    "are what we need for analysis. dlatk can use these two tables to extract topic assignments for a corpus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic wordclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir -p {out_d}/topic_wordclouds\n",
    "%rm -rf {out_d}/topic_wordclouds/*\n",
    "%cd {out_d}/topic_wordclouds\n",
    "\n",
    "!dlatkInterface.py \\\n",
    "    --lexicondb {database} \\\n",
    "    --topic_lexicon {topic_ll_table} \\\n",
    "    --make_all_topic_wordclouds \\\n",
    "    --tagcloud_colorscheme blue \\\n",
    "    --output 'output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make columns with time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "alter table {msgs_table} drop column date;\n",
    "alter table {msgs_table} add column date DATE;\n",
    "update {msgs_table}\n",
    "set date = date(date_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter 1grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dlatkInterface.py \\\n",
    "    --corpdb {database} \\\n",
    "    --corptable {msgs_table} \\\n",
    "    --correl_field message_id \\\n",
    "    --feat_table '{feat_1gram_pruned_table}' \\\n",
    "    --feat_occ_filter --set_p_occ 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select count(distinct(feat)) from feat_pruned$1gram$4chan2$message_id$16to16$0_0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlate 1grams with each hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_d = '~/project'\n",
    "out_name = '1grams'\n",
    "!mkdir -p {out_d}\n",
    "!rm -rf {out_d}/{out_name}*\n",
    "\n",
    "!dlatkInterface.py \\\n",
    "    --corpdb {database} \\\n",
    "    --corptable {msgs_table} \\\n",
    "    --correl_field message_id \\\n",
    "    --correlate --rmatrix --csv --sort \\\n",
    "    --feat_table '{feat_1gram_0_0001_table}' \\\n",
    "    --outcome_table {msgs_table} \\\n",
    "    --outcomes only_hour \\\n",
    "    --categories_to_binary only_hour \\\n",
    "    --tagcloud --make_wordclouds \\\n",
    "    --lexicondb {database} \\\n",
    "    --topic_lexicon {topic_ll_table} \\\n",
    "    --output_name {out_d}/{out_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract from lexicon, correlate with time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = !dlatkInterface.py \\\n",
    "    --lexicondb {database} \\\n",
    "    --corpdb {database} \\\n",
    "    --corptable {msgs_table} \\\n",
    "    --correl_field message_id \\\n",
    "    --add_lex_table -l {topics_cp_table} --weighted_lexicon  2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_d = '~/project'\n",
    "out_name = '1gram_project_hour'\n",
    "!mkdir -p {out_d}\n",
    "!rm -rf {out_d}/{out_name}*\n",
    "\n",
    "!dlatkInterface.py \\\n",
    "    --corpdb {database} \\\n",
    "    --corptable {msgs_table} \\\n",
    "    --correl_field message_id \\\n",
    "    --correlate --rmatrix --csv --sort \\\n",
    "    --outcome_table {msgs_table} \\\n",
    "    --outcomes only_hour \\\n",
    "    --categories_to_binary only_hour \\\n",
    "    --feat_table '{feat_hour_msg_table}' \\\n",
    "    --topic_tagcloud --make_topic_wordclouds \\\n",
    "    --tagcloud_colorscheme blue \\\n",
    "    --lexicondb {database} \\\n",
    "    --topic_lexicon {topic_ll_table} \\\n",
    "    --output_name {out_d}/{out_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract and correlate LIWC with time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = !dlatkInterface.py \\\n",
    "    --corpdb {database} \\\n",
    "    --corptable {msgs_table} \\\n",
    "    --correl_field message_id \\\n",
    "    --add_lex_table -l LIWC2015  2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open('output.txt','w').write('\\n'.join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_d = '~/project'\n",
    "out_name = '1gram_project_hour_LIWC'\n",
    "!mkdir -p {out_d}\n",
    "!rm -rf {out_d}/{out_name}*\n",
    "\n",
    "output = !dlatkInterface.py \\\n",
    "    --corpdb {database} \\\n",
    "    --corptable {msgs_table} \\\n",
    "    --correl_field message_id \\\n",
    "    --correlate --rmatrix --csv --sort \\\n",
    "    --feat_table '{feat_LIWC_table}' \\\n",
    "    --outcome_table {msgs_table} \\\n",
    "    --outcomes only_hour \\\n",
    "    --categories_to_binary only_hour \\\n",
    "    --tagcloud --make_wordclouds \\\n",
    "    --tagcloud_colorscheme blue \\\n",
    "    --lexicondb {database} \\\n",
    "    --topic_lexicon {topic_ll_table} \\\n",
    "    --output_name {out_d}/{out_name} 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210589"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('output.txt','w').write('\\n'.join(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trying out fb lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_d = '~/project'\n",
    "out_name = '1gram_project_fb'\n",
    "!mkdir -p {out_d}\n",
    "!rm -rf {out_d}/{out_name}*\n",
    "\n",
    "output = !dlatkInterface.py \\\n",
    "    --corpdb {database} \\\n",
    "    --corptable {msgs_table} \\\n",
    "    --correl_field message_id \\\n",
    "    --correlate --rmatrix --csv --sort \\\n",
    "    --feat_table '{feat_fb_table}' \\\n",
    "    --outcome_table {msgs_table} \\\n",
    "    --outcomes only_hour \\\n",
    "    --categories_to_binary only_hour \\\n",
    "    --topic_tagcloud --make_topic_wordclouds \\\n",
    "    --topic_lexicon topics_fb2k_freq \\\n",
    "    --tagcloud_colorscheme blue \\\n",
    "    --output_name {out_d}/{out_name} 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find words driving a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_d = '~/project'\n",
    "out_name = '1gram_project_FUNCTION'\n",
    "!mkdir -p {out_d}\n",
    "!rm -rf {out_d}/{out_name}*\n",
    "\n",
    "ouotput = !dlatkInterface.py \\\n",
    "    --corpdb {database} \\\n",
    "    --corptable {msgs_table} \\\n",
    "    --correl_field message_id \\\n",
    "    --correlate --csv --rmatrix \\\n",
    "    --feat_table '{feat_1gram_0_0001_table}' \\\n",
    "    --outcome_table {msgs_table} \\\n",
    "    --outcomes only_hour \\\n",
    "    --categories_to_binary only_hour \\\n",
    "    --tagcloud --make_wordclouds \\\n",
    "    --whitelist --lex_table LIWC2015 --categories 'FUNCTION' \\\n",
    "    --output_name {out_d}/{out_name} 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5294035"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('output.txt','w').write('\\n'.join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
